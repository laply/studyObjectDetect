
unified Detection 

yolo가 기존의 Object Detection과 가장 크게 구분되는 부분은 
region proposal, classification 이렇게 두단계로 나누어서 진행하던 방식에서
region proposal단계를 제거하고 한번에 Object Detection을 수행하는 구조를 갖는다는 것이다.


먼저 입력이미지를 SxS 그리드 영역으로 나누고 (가상) 각 그리드 영역에서 먼저 물체가 있을만한 영역에 해당하는 B개의
Bounding Box를 예측한다. 

이는 x, y, w, h로 나타내어 지는데 (x, y)는 바운딩 박스의 중심점 좌표, (w, h) 넓이와 높이

다음으로 해당 박스의 신뢰도를 나타내는 confidence를 계산한다. 

이는 해당 그리드에 물체가 있을 확률 Pr(Object)와 예측한 박스와 Ground Truth 박스와의 겹치는 영역을 
비율로 나타내는 IoU를 곱해서 계산한다.

confidence = Pr(Object) * IoU(truth/pred)

그 다음 각각 그리드마다 C개의 클래스에 대하여 해당 클래스일 확률을 계산한다.
(yolo에서는 배경 포함 되지 않음)

Pr(Class_i|Object)


네트워크의 출력인 7x7x30 피쳐맵

여기 안에는 우리가 앞서서 말했던 그리드 별 바운딩 박스와 신뢰도 지수, 그리고 각 클래스 별 예측값들이 담겨져 있습니다.

7x7은 그리드를 의미하며, 각각의 인덱스는 총 30차원의 백터 값을 갖는다.
총 B개의 바운딩 박스를 갖는데 논문에서는 이를 2로 설정하였고,

30차원 백터 가운데 앞의 10개의 수는 이 두개의 박스를 의미한다.
하나의 박스는 중심점 x, y 넓이 높이 w, h 신뢰도 지수 c 총 5개 차원 백터로 나타낼 수 있으며 두개박스는 10차원을 의미한다.

그 다음 오는 20차원 백터는 해당 인덱스가 특정 클래스일 확률 값, 여기서는 20인 데이터셋을 사용하였기 때문에 20차원으로 표현된다.

박스의 신뢰도와 클래스별 확률 값은 각각
Pr(Object) * IoU(truth/pred), Pr(Class_i|Object)로 구했다.
따라서 이 둘을 곱해주면  Pr(Class_i)*IoU(truth/pred)가 되고 이는 곧 해당 박스가 특정 클래스일 확률이된다.
이 작업을 인덱스 i의 모든 B개 바운딩 박스에 적용하고 SxS 인덱스에 에 적용한다.

이제 이렇게 구한 벡터들을 모두 모은 뒤 일렬로 나란히 세우면, 가장 위 차원부터 각 클래스별로 전체 바운딩 박스에서의 확률 값을 구할 수 있습니다.
물론 여기에는 동일한 물체에 중복되어 지정된 박스들도 있을 것입니다.
이를 방지하고자 NMS라는 작업을 거치게 된다. 이제 NMS를 거쳐서 살아남은 최종 결과를 이미지 위에 그려주는 작업만 남았다.


Loss Function

img 확인 
